# Clonet Project Statistics

Generated on: October 8, 2025

## 📊 Project Overview

### Total Project Metrics
- **Total Files**: 31 files (excluding node_modules)
- **Total Lines of Code**: 2,071 lines
- **Total Project Size**: 60.69 KB
- **Average File Size**: 1.96 KB
- **Total Directories**: 11 directories

## 🗂️ File Distribution by Type

| File Type | Count | Purpose |
|-----------|-------|---------|
| JavaScript (.js) | 10 | Core application logic |
| JSON (.json) | 3 | Configuration files |
| CSS (.css) | 2 | Styling |
| Docker (.dev, .dockerignore) | 4 | Containerization |
| YAML (.yml) | 2 | Docker Compose configs |
| Environment (.env, .example) | 2 | Environment variables |
| Documentation (.md) | 1 | Project documentation |
| HTML (.html) | 1 | Frontend template |
| SQL (.sql) | 1 | Database initialization |
| Shell (.sh) | 1 | Utility scripts |
| Other | 5 | Miscellaneous configs |

## 🏗️ Architecture Breakdown

### Frontend (React)
- **Files**: 11 files
- **Lines of Code**: 309 lines
- **Technologies**: React 18, CSS3, HTML5
- **Key Components**:
  - Main App component with Spark status monitoring
  - Responsive CSS styling
  - Integration with backend API

### Backend (Node.js + Apache Spark)
- **Files**: 13 files
- **Lines of Code**: 1,283 lines
- **Technologies**: Node.js, Express.js, Apache Spark, Swagger
- **Key Components**:
  - SparkSession management (172 lines)
  - Spark Data Service (248 lines)
  - API routes with Swagger docs (312 lines)
  - Main server setup (196 lines)
  - Swagger configuration (270 lines)

### Infrastructure & Configuration
- **Docker & Config Files**: 11 files (358 lines)
- **Database Files**: 1 file (17 lines)
- **Documentation**: 1 file (271 lines)

## 📈 Code Distribution

### Languages by Lines of Code
1. **JavaScript**: 1,375 lines (66.4%)
2. **YAML**: 191 lines (9.2%)
3. **Markdown**: 271 lines (13.1%)
4. **CSS**: 110 lines (5.3%)
5. **JSON**: 72 lines (3.5%)
6. **HTML**: 20 lines (1.0%)
7. **SQL**: 17 lines (0.8%)
8. **Other**: 15 lines (0.7%)

## 🎯 Key Features by Code Volume

### Core Functionality
- **Spark Integration**: 420 lines (SparkSession + Data Service)
- **API Documentation**: 582 lines (Swagger + route docs)
- **Server & Middleware**: 196 lines
- **Frontend Components**: 309 lines
- **Docker Configuration**: 358 lines

### Advanced Features
- ✅ Apache Spark data processing
- ✅ Interactive Swagger API documentation
- ✅ Docker containerization
- ✅ Health monitoring endpoints
- ✅ User analytics and insights
- ✅ Pagination and search capabilities
- ✅ Responsive React frontend

## 🔧 Development Metrics

### Code Quality Indicators
- **Average lines per JavaScript file**: 137.5 lines
- **Largest file**: users.js (312 lines) - API routes
- **Most complex component**: SparkDataService (248 lines)
- **Documentation coverage**: Comprehensive (Swagger + README)

### Project Complexity
- **Backend/Frontend ratio**: 4.2:1 (lines of code)
- **Configuration overhead**: 17.3% of total codebase
- **Documentation ratio**: 13.1% of total codebase

## 🚀 Technology Stack Summary

### Core Technologies
- **Frontend**: React 18, Modern CSS, Responsive Design
- **Backend**: Node.js, Express.js, Apache Spark 3.5
- **Database**: MySQL 8.0 with JDBC integration
- **Containerization**: Docker, Docker Compose
- **Documentation**: Swagger/OpenAPI 3.0

### Development Tools
- **API Testing**: Interactive Swagger UI
- **Database Management**: phpMyAdmin
- **Monitoring**: Spark Web UI, Health endpoints
- **Environment Management**: Docker containers

## 📋 File Structure Summary

```
clonet/ (31 files, 2,071 lines)
├── frontend/ (11 files, 309 lines)
│   ├── React components and styling
│   └── Build configuration
├── backend/ (13 files, 1,283 lines)
│   ├── Spark integration
│   ├── API routes with Swagger
│   └── Server configuration
├── database/ (1 file, 17 lines)
│   └── SQL initialization
├── docker/ (1 file, 3 lines)
│   └── Spark JAR configuration
└── Root configs (5 files, 459 lines)
    ├── Docker Compose
    ├── Environment files
    └── Documentation
```

---

*This project demonstrates a modern, scalable architecture with enterprise-grade data processing capabilities using Apache Spark, comprehensive API documentation, and full containerization for easy deployment.*